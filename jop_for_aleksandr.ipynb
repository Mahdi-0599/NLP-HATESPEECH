{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "jop-for-aleksandr.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahdi-0599/NLP-HATESPEECH/blob/master/jop_for_aleksandr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H69-_LjLta6k"
      },
      "source": [
        "# Homework 3 due Monday 10/26 by midnight\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKEkc2pIta6l"
      },
      "source": [
        "# 1. Convolution operator \n",
        "\n",
        "## Sample code\n",
        "The code below illustrates how to load an image using the Pillow package and how to obtain a response to a convolutional filter. \n",
        "\n",
        "If you are running your own Jupyter notebook server (not Google Colab), you might need to install the following packages before starting Jupyter notebook:\n",
        "* the Pillow package: `pip install pillow`\n",
        "* the scikit image processing package: `pip install scikit-image`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iO7h5ONtta6m"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from scipy import signal\n",
        "from skimage import filters\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread, imshow\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "import io\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YvxSSqNeta6r"
      },
      "source": [
        "img = cv.imread('../input/19312276/19312276.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UXpYFDFnta6t"
      },
      "source": [
        "px = img[100,100]\n",
        "print( px )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "F_k5obBata6w"
      },
      "source": [
        "blue = img[100,100,0]\n",
        "print( blue )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DdRPeh3jta6y"
      },
      "source": [
        "img[100,100] = [255,255,255]\n",
        "print( img[100,100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r1KSnIOEta62"
      },
      "source": [
        "img.item(10,10,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VUdVd6lXta65"
      },
      "source": [
        "img.itemset((10,10,2),100)\n",
        "img.item(10,10,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_nARgWJjta69"
      },
      "source": [
        "print( img.shape )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aFOmFZGYta6_"
      },
      "source": [
        "print( img.size )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "M_8DxASVta7C"
      },
      "source": [
        "print( img.dtype )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FKeXenwIta7E"
      },
      "source": [
        "ball = img[280:340, 330:390]\n",
        "img[273:333, 100:160] = ball"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CI3TUR5pta7H"
      },
      "source": [
        "b,g,r = cv.split(img)\n",
        "img = cv.merge((b,g,r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GU9SkWiVta7K"
      },
      "source": [
        "img[:,:,2] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CcS69Bl-ta7N"
      },
      "source": [
        "# Read an image and convert to gray using the Image class from Pillow\n",
        "imgPath = '/Volumes/GoogleDrive/My Drive/Courses/CSC375-DeepLearning/Downloads/cats_and_dogs_small/'\n",
        "imgFile = imgPath + '../input/19312276'\n",
        "img = Image.open('../input/19312276/19312276.jpg')\n",
        "# Convert to gray\n",
        "imgGray = img.convert('L') \n",
        "plt.imshow(imgGray, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bzhzUOxbta7P"
      },
      "source": [
        "# Convert gray image to Numpy array, normalize, and show some stats\n",
        "gray = np.array(imgGray) / 255.0\n",
        "print(\"Image shape:\", gray.shape)\n",
        "print(\"Maximum value:\", gray.max())\n",
        "print(\"Minimum value:\", gray.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JqHGuiwdta7R"
      },
      "source": [
        "# Define a Sobel filter for edge detection\n",
        "sobel_y = np.array([[ 1.,  0., -1.],[ 2.,  0., -2.],[ 1.,  0., -1.]])\n",
        "# Obtain a response to this filter with the sample image\n",
        "grayFiltered = signal.convolve2d(gray, sobel_y, mode='valid')\n",
        "# Print info about the filter and its response\n",
        "print(sobel_y)\n",
        "print(\"Response shape:\", grayFiltered.shape)\n",
        "print(\"Response maximum value:\", grayFiltered.max())\n",
        "print(\"Response minimum value:\", grayFiltered.min())\n",
        "\n",
        "# Plot the response as in image (Pyplot will rescale response to show as image intensities)\n",
        "plt.imshow(grayFiltered, cmap='gray')\n",
        "# If you want to threshold into a black and white\n",
        "# plt.imshow(np.abs(grayFiltered) > 0.15*grayFiltered.max(), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ2M7uS9ta7T"
      },
      "source": [
        "## 1.1 Observing the response of convolutional filtering (10%)\n",
        "* Open an image of your own, convert it to gray scale. \n",
        "* Define a Laplacian of Gaussian filter (see e.g.[web resource](https://theailearner.com/2019/05/25/laplacian-of-gaussian-log/)) in the same way the Sobel filter is defined in the sample code above.\n",
        "* Convolve your gray-scaled image with the Laplacian filter.\n",
        "* Display the original image, the Laplacian filter, and the Laplacian response as images horizontally in a single figure.\n",
        "\n",
        "This code shows how to place images horizontal in a single figure:\n",
        "<code>\n",
        "#plt.figure(figsize=(12,12))\n",
        "#plt.subplot(1,3,1)\n",
        "#plt.imshow(gray_image, cmap='gray')\n",
        "#plt.subplot(1,3,2)\n",
        "#plt.imshow(laplacian_filter, cmap='gray')\n",
        "#plt.subplot(1,3,3)\n",
        "#plt.imshow(response, cmap='gray')\n",
        "#plt.show()\n",
        "</code>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uRLRBRXHta7U"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "BLUE = [255,0,0]\n",
        "img1 = cv.imread('../input/19312276/19312276.jpg')\n",
        "replicate = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REPLICATE)\n",
        "reflect = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REFLECT)\n",
        "reflect101 = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REFLECT_101)\n",
        "wrap = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_WRAP)\n",
        "constant= cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_CONSTANT,value=BLUE)\n",
        "plt.subplot(231),plt.imshow(img1,'gray'),plt.title('ORIGINAL')\n",
        "plt.subplot(232),plt.imshow(replicate,'gray'),plt.title('REPLICATE')\n",
        "plt.subplot(233),plt.imshow(reflect,'gray'),plt.title('REFLECT')\n",
        "plt.subplot(234),plt.imshow(reflect101,'gray'),plt.title('REFLECT_101')\n",
        "plt.subplot(235),plt.imshow(wrap,'gray'),plt.title('WRAP')\n",
        "plt.subplot(236),plt.imshow(constant,'gray'),plt.title('CONSTANT')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iYsotsnuta7X"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "rgb = cv.imread(\"../input/19312276/19312276.jpg\")\n",
        "weight=rgb.shape[0]\n",
        "height=rgb.shape[1]\n",
        "number=rgb.shape[2]\n",
        "print(\"Original image size:\\n\"\"weight: %d \\nheight: %d \\nnumber: %d\" %(weight,height,number)) #Check image size\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sqtHB-rsta7c"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "img = Image.open(\"../input/19312276/19312276.jpg\")\n",
        "pix = img.load()\n",
        "cols,rows = img.size\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bUOrGO0rta7e"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Define gaussian, sobel, and laplacian (edge) filters\n",
        "\n",
        "gaussian = (1/9)*np.array([[1, 1, 1],\n",
        "                           [1, 1, 1],\n",
        "                           [1, 1, 1]])\n",
        "\n",
        "sobel_x= np.array([[-1, 0, 1],\n",
        "                   [-2, 0, 2],\n",
        "                   [-1, 0, 1]])\n",
        "\n",
        "sobel_y= np.array([[-1,-2,-1],\n",
        "                   [0, 0, 0],\n",
        "                   [1, 2, 1]])\n",
        "\n",
        "# laplacian, edge filter\n",
        "laplacian=np.array([[0, 1, 0],\n",
        "                    [1,-4, 1],\n",
        "                    [0, 1, 0]])\n",
        "\n",
        "filters = [gaussian, sobel_x, sobel_y, laplacian]\n",
        "filter_name = ['gaussian','sobel_x', \\\n",
        "                'sobel_y', 'laplacian']\n",
        "\n",
        "\n",
        "# perform a fast fourier transform on each filter\n",
        "# and create a scaled, frequency transform image\n",
        "f_filters = [np.fft.fft2(x) for x in filters]\n",
        "fshift = [np.fft.fftshift(y) for y in f_filters]\n",
        "frequency_tx = [np.log(np.abs(z)+1) for z in fshift]\n",
        "\n",
        "# display 4 filters\n",
        "for i in range(len(filters)):\n",
        "    plt.subplot(2,2,i+1),plt.imshow(frequency_tx[i],cmap = 'gray')\n",
        "    plt.title(filter_name[i]), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1YYWNNitta7g"
      },
      "source": [
        "\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import scipy.ndimage as nd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import data    \n",
        "\n",
        "# lena = sp.misc.lena() this function was deprecated in version 0.17\n",
        "img = Image.open('../input/19312276/19312276.jpg') # use a standard image from skimage instead\n",
        "LoG = nd.gaussian_laplace(img , 2)\n",
        "thres = np.absolute(LoG).mean() * 0.75\n",
        "output = sp.zeros(LoG.shape)\n",
        "w = output.shape[1]\n",
        "h = output.shape[0]\n",
        "\n",
        "for y in range(1, h - 1):\n",
        "    for x in range(1, w - 1):\n",
        "        patch = LoG[y-1:y+2, x-1:x+2]\n",
        "        p = LoG[y, x]\n",
        "        maxP = patch.max()\n",
        "        minP = patch.min()\n",
        "\n",
        "\n",
        "plt.imshow(output)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuv2Sn8mta7j"
      },
      "source": [
        "1. ## 1.2 Simple pattern matching (15%)\n",
        "One simple (but not very effective) way to do pattern matching, is to convolve an image with a small patch containing the object we are looking to find. The largest values in the response map show places in the image where the patch may be likely found. Thresholding can help find the locations of the largest response values. As an example, the code below attempts to find the nose of the cat image loaded in the sample code above.\n",
        "\n",
        "<code>\n",
        "# Location of the cat's nose\n",
        "#patch = gray[325:375,350:400]\n",
        "# Subtract the mean from the patch before applying it\n",
        "#filteredImg = signal.convolve2d(gray, patch - patch.mean() , mode='valid')\n",
        "# Threshold to 50% of the maximum response value\n",
        "#.imshow(filteredImg > 0.5 * filteredImg.max(), cmap='gray')\n",
        "#plt.show()\n",
        "</code>\n",
        "\n",
        "* Apply the technique above to your own image (select your own patch from it) and see if you can use it to identify the location of the patch via thresholding. If you feel like trying, see if you can find [Waldo](https://gallery.mailchimp.com/5f6b6be1430c874914e00696e/images/1_Wally.png) in this [image](https://www.123sonography.com/sites/default/files/article/images/2_Waldo_Illustration.png)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aHTJ61oQta7j"
      },
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "imgL = cv.imread('../input/19312276/19312276.jpg',0)\n",
        "imgR = cv.imread('../input/19312276/19312276.jpg',0)\n",
        "stereo = cv.StereoBM_create(numDisparities=16, blockSize=15)\n",
        "disparity = stereo.compute(imgL,imgR)\n",
        "plt.imshow(disparity,'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOePQboqta7l"
      },
      "source": [
        "# 2. Effect of downsampling and filtering (25%)\n",
        "Downsampling an image while repeatedly applying a filter is a well-known technique in computer vision for identifying features at multiple hierarchical scales. The idea is simple: apply a filter and obtain a response, then  downsample the image by some factor and apply the filter again at that scale. Do this iteratively until the image cannot be downsampled any further. \n",
        "\n",
        "Write and test code to do the following:\n",
        "* Load an image and create a Laplacian filter of size (3,3)\n",
        "* Calculate the maximum number of times, k, that an image can be downsampled by a factor of 2. *Hint: calculate log2 of the minimum of your image height and width.*\n",
        "* Iterate a loop k times. At each iteration, apply the filter to the image, save the response map, and then downsample the image by a factor of 2.  \n",
        "* Plot all the responses horizontally as images in the same figure.\n",
        "\n",
        "Here is how to downsample an image by a factor of 2:\n",
        "<code>\n",
        "#smaller_img = rescale(img, 0.5, anti_aliasing=False)    \n",
        "</code>\n",
        "\n",
        "Briefly discuss the effect of downsampling in the filtering process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wTdb0akDta7m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0lJxxkuOta7q"
      },
      "source": [
        "# Use the rescale() function from the Scikit Image Processing package\n",
        "from skimage.transform import rescale\n",
        "import sys\n",
        "import cv2 as cv\n",
        "def main(argv):\n",
        "    print(\"\"\"\n",
        "    Zoom In-Out demo\n",
        "    ------------------\n",
        "    * [i] -> Zoom [i]n\n",
        "    * [o] -> Zoom [o]ut\n",
        "    * [ESC] -> Close program\n",
        "    \"\"\")\n",
        "    \n",
        "    filename = argv[0] if len(argv) > 0 else 'chicky_512.png'\n",
        "    # Load the image\n",
        "    src = cv.imread(cv.samples.findFile('../input/19312276/19312276.jpg'))\n",
        "    # Check if image is loaded fine\n",
        "    if src is None:\n",
        "        print ('Error opening image!')\n",
        "        print ('Usage: pyramids.py [image_name -- default ../data/chicky_512.png] \\n')\n",
        "        return -1\n",
        "    \n",
        "    while 1:\n",
        "        rows, cols, _channels = map(int, src.shape)\n",
        "        \n",
        "        cv.imshow('Pyramids Demo', src)\n",
        "        \n",
        "        k = cv.waitKey(0)\n",
        "        if k == 27:\n",
        "            break\n",
        "            \n",
        "        elif chr(k) == 'i':\n",
        "            src = cv.pyrUp(src, dstsize=(2 * cols, 2 * rows))\n",
        "            print ('** Zoom In: Image x 2')\n",
        "            \n",
        "        elif chr(k) == 'o':\n",
        "            src = cv.pyrDown(src, dstsize=(cols // 2, rows // 2))\n",
        "            print ('** Zoom Out: Image / 2')\n",
        "            \n",
        "    cv.destroyAllWindows()\n",
        "    return 0\n",
        "if __name__ == \"__main__\":\n",
        "    main(sys.argv[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LWVYi3Lpta7t"
      },
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "img = cv.imread('../input/19312276/19312276.jpg')\n",
        "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "sift = cv.SIFT_create()\n",
        "kp = sift.detect(gray,None)\n",
        "img=cv.drawKeypoints(gray,kp,img)\n",
        "cv.imwrite('sift_keypoints.jpg',img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2tCm4S_jta7w"
      },
      "source": [
        "img=cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "cv.imwrite('../input/19312276/19312276.jpg',img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sU5jVhNZta7y"
      },
      "source": [
        "sift = cv.SIFT_create()\n",
        "kp, des = sift.detectAndCompute(gray,None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEKFggKsta70"
      },
      "source": [
        "# 3. Visualizing Filters and their Responses (50%)\n",
        "\n",
        "Section 5.4 introduces three ways to visualize what a convolutional neural network learns:\n",
        "* Visualizing outputs (intermediate activations) produced by convolutional layers\n",
        "* Visualizing filters learned by displaying the patterns they are meant to respond to\n",
        "* Visualizing the parts of an image using heatmaps that lead a convolutional neural network to a classification decision\n",
        "\n",
        "For this part, pick and explore one of these three visualization techniques discussed in section 5.4 of the textbook. Demonstrate your work in the following ways:\n",
        "* Reproduce the output of all the sample code in the the subsection of your choice. You can find the sample code in Canvas.\n",
        "* Provide additional insight in a paragraph of two(more than what's covered in the subsection) into the visualization method you chose. You can do this by looking at resources on the web. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hnreJ6a2ta71"
      },
      "source": [
        "from __future__ import print_function\n",
        "import cv2 as cv\n",
        "import argparse\n",
        "max_lowThreshold = 100\n",
        "window_name = 'Edge Map'\n",
        "title_trackbar = 'Min Threshold:'\n",
        "ratio = 3\n",
        "kernel_size = 3\n",
        "def CannyThreshold(val):\n",
        "    low_threshold = val\n",
        "    img_blur = cv.blur(src_gray, (3,3))\n",
        "    detected_edges = cv.Canny(img_blur, low_threshold, low_threshold*ratio, kernel_size)\n",
        "    mask = detected_edges != 0\n",
        "    dst = src * (mask[:,:,None].astype(src.dtype))\n",
        "    cv.imshow(window_name, dst)\n",
        "parser = argparse.ArgumentParser(description='Code for Canny Edge Detector tutorial.')\n",
        "parser.add_argument('--input', help='Path to input image.', default='fruits.jpg')\n",
        "args = parser.parse_args()\n",
        "src = cv.imread(cv.samples.findFile(args.input))\n",
        "if src is None:\n",
        "    print('Could not open or find the image: ', args.input)\n",
        "    exit(0)\n",
        "src_gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
        "cv.namedWindow(window_name)\n",
        "cv.createTrackbar(title_trackbar, window_name , 0, max_lowThreshold, CannyThreshold)\n",
        "CannyThreshold(0)\n",
        "cv.waitKey()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0qrBiy4Rta73"
      },
      "source": [
        "import sys\n",
        "import cv2 as cv\n",
        "def main(argv):\n",
        "    print(\"\"\"\n",
        "    Zoom In-Out demo\n",
        "    ------------------\n",
        "    * [i] -> Zoom [i]n\n",
        "    * [o] -> Zoom [o]ut\n",
        "    * [ESC] -> Close program\n",
        "    \"\"\")\n",
        "    \n",
        "    filename = argv[0] if len(argv) > 0 else 'chicky_512.png'\n",
        "    # Load the image\n",
        "    src = cv.imread(cv.samples.findFile('../input/19312276/19312276.jpg'))\n",
        "    # Check if image is loaded fine\n",
        "    if src is None:\n",
        "        print ('Error opening image!')\n",
        "        print ('Usage: pyramids.py [image_name -- default ../data/chicky_512.png] \\n')\n",
        "        return -1\n",
        "    \n",
        "    while 1:\n",
        "        rows, cols, _channels = map(int, src.shape)\n",
        "        \n",
        "        cv.imshow('Pyramids Demo', src)\n",
        "        \n",
        "        k = cv.waitKey(0)\n",
        "        if k == 27:\n",
        "            break\n",
        "            \n",
        "        elif chr(k) == 'i':\n",
        "            src = cv.pyrUp(src, dstsize=(2 * cols, 2 * rows))\n",
        "            print ('** Zoom In: Image x 2')\n",
        "            \n",
        "        elif chr(k) == 'o':\n",
        "            src = cv.pyrDown(src, dstsize=(cols // 2, rows // 2))\n",
        "            print ('** Zoom Out: Image / 2')\n",
        "            \n",
        "    cv.destroyAllWindows()\n",
        "    return 0\n",
        "if __name__ == \"__main__\":\n",
        "    main(sys.argv[1:])\n",
        "filename = argv[0] if len(argv) > 0 else 'chicky_512.png'\n",
        "    # Load the image\n",
        "src = cv.imread(cv.samples.findFile('../input/19312276/19312276.jpg'))\n",
        "    # Check if image is loaded fine\n",
        "if src is None:\n",
        "    print ('Error opening image!')\n",
        "    print ('Usage: pyramids.py [image_name -- default ../data/chicky_512.png] \\n')\n",
        "    return -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nucV8dhkta76"
      },
      "source": [
        "#Method3: Extracting Edge Features\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.filters import prewitt_h,prewitt_v \n",
        "\n",
        "#reading the image \n",
        "image = imread('../input/19312276/19312276.jpg',as_gray=True)\n",
        "\n",
        "#calculating horizontal edges using prewitt kernel\n",
        "edges_prewitt_horizontal = prewitt_h(image)\n",
        "#calculating vertical edges using prewitt kernel\n",
        "edges_prewitt_vertical = prewitt_v(image)\n",
        "\n",
        "imshow(edges_prewitt_vertical, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SGRDXbA1ta79"
      },
      "source": [
        "edges_prewitt_horizontal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YpqKEkEcta7_"
      },
      "source": [
        "edges_prewitt_vertical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3x8P435ta8C"
      },
      "source": [
        ""
      ]
    }
  ]
}